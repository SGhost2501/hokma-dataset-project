# hokma-dataset-project

ðŸš€ Codex Instruction: Generate Hokma LLM Dataset for Fine-Tuning
Objective:
Create a dataset to fine-tune a chatbot that accurately simulates Hokmaâ€™s personality and knowledge. The dataset will consist of input prompts and Hokma-style outputs, enriched with metadata for flexible training.

ðŸ“Œ Input prompts requirements:

Each input should reference an abnormality (by name).

Include a wide variety of question types:

Moral: e.g. What lesson does {Name} offer?

Procedural: e.g. How should an agent handle {Name}?

Philosophical: e.g. How does {Name} reflect the Cityâ€™s sins?

Classification-focused: e.g. Why is {Name} classified as {Risk Level}?

Handling-focused: e.g. What is the key to surviving an encounter with {Name}?

Ensure prompts are phrased in Hokmaâ€™s thematic tone (serious, reflective).

ðŸ“Œ Output response requirements:

Hokma-style language: authoritative, calm, thoughtful, reflective.

Include factual data from abnormality (classification, attack type, e-boxes, qliphoth counter).

Optionally weave in lore or philosophical commentary (about the City, humanity, sin, order).

Each output must be unique and contextually relevant to its input.

ðŸ“Œ Metadata for each record (add alongside input/output):

json
Copy
Edit
{
  "classification": "{Risk Level}",
  "attack_type": "{Attack Type}",
  "e_boxes": {E-Boxes},
  "qliphoth_counter": "{Qliphoth Counter}",
  "theme": "abnormality",
  "source_file": "generate_abno_prompts.py",
  "reviewed": false,
  "auto_generated": true,
  "created_at": "{ISO timestamp}"
}
ðŸ“Œ Dataset size and balance:

Target ~2000 prompt/response pairs.

Ensure variety so that no abnormality or template dominates the dataset disproportionately.

Distribute prompts evenly across moral, procedural, philosophical, classification, and handling categories.

ðŸ“Œ Output format:

JSONL, with one record per line:

json
Copy
Edit
{ "input": "...", "output": "...", "classification": "...", "attack_type": "...", ... }
Compatible with OpenAI fine-tuning tools.

ðŸ‘‰ Please generate and output the dataset, ready for inspection and fine-tuning.
